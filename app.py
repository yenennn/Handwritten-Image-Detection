# -*- coding: utf-8 -*-
"""assignment_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mU28zOzehS986Nto5B-rsMOiBE4SoSZL

## Handwritten Image Detection with Keras using MNIST data

In this assignment we will work with image data: specifically, the famous MNIST data set.  This data set contains 70,000 images of handwritten digits in grayscale (0=black, 255 = white).  The images are 28 pixels by 28 pixels for a total of 784 pixels.  This is quite small by image standards.  Also, the images are well centered and isolated.  This makes this problem solvable with standard fully connected neural nets without too much pre-work.

In the first part of this notebook, we will walk you through loading in the data, building a network, and training it.  Then it will be your turn to try different models and see if you can improve performance
"""

# Commented out IPython magic to ensure Python compatibility.
# Preliminaries

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

"""Let's explore the dataset a little bit"""

# Load the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train[0].shape

#Let's just look at a particular example to see what is inside

x_train[333]  ## Just a 28 x 28 numpy array of ints from 0 to 255

# What is the corresponding label in the training set?
y_train[333]

# Let's see what this image actually looks like

plt.imshow(x_train[333], cmap='Greys_r')
plt.show()

# this is the shape of the np.array x_train
# it is 3 dimensional.
print(x_train.shape, 'train samples')
print(x_test.shape, 'test samples')

## For our purposes, these images are just a vector of 784 inputs, so let's convert
x_train = x_train.reshape(len(x_train), 28*28)
x_test = x_test.reshape(len(x_test), 28*28)

## Keras works with floats, so we must cast the numbers to floats
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

## Normalize the inputs so they are between 0 and 1
x_train /= 255
x_test /= 255

# convert class vectors to binary class matrices (one-hot encoding)
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

y_train[333]  # now the digit k is represented by a 1 in the kth entry (0-indexed) of the length 10 vector

# We will build a model with one hidden layer of size 64
# Fully connected inputs at each layer
# We will use dropout of .2 to help regularize
model_1 = Sequential()
model_1.add(Dense(64, activation='relu', input_shape=(784,)))
model_1.add(Dropout(0.2))
model_1.add(Dense(10, activation='softmax'))

## Note that this model has a LOT of parameters
model_1.summary()

# Let's compile the model
learning_rate = .0015
model_1.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=learning_rate),
              metrics=['accuracy'])
# note that `categorical cross entropy` is the natural generalization
# of the loss function we had in binary classification case, to multi class case

# And now let's fit.

batch_size = 32  # mini-batch with 32 examples
epochs = 10
history = model_1.fit(
    x_train, y_train,
    batch_size=batch_size,
    epochs=epochs,
    verbose=1,
    validation_data=(x_test, y_test))

## We will use Keras evaluate function to evaluate performance on the test set

score = model_1.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

def plot_loss_accuracy(history):
    fig = plt.figure(figsize=(12, 6))
    ax = fig.add_subplot(1, 2, 1)
    ax.plot(history.history["loss"],'r-x', label="Train Loss")
    ax.plot(history.history["val_loss"],'b-x', label="Validation Loss")
    ax.legend()
    ax.set_title('cross_entropy loss')
    ax.grid(True)


    ax = fig.add_subplot(1, 2, 2)
    ax.plot(history.history["accuracy"],'r-x', label="Train Accuracy")
    ax.plot(history.history["val_accuracy"],'b-x', label="Validation Accuracy")
    ax.legend()
    ax.set_title('accuracy')
    ax.grid(True)
    plt.show()


plot_loss_accuracy(history)

"""## Assignment

### PART-1: Overfitting
Create another model called "model_1_a" with the following properties:

1. Its architecture is same as "model_1" except that it doesn't employ dropout.

2. Train the new model as before (for 10 epochs) and plot the loss and accuracy values.

From the plots, you should be able to detect an undesirable behavior. Describe this behavior. Explain why it happened.
"""

# Load the data
(x_train_a, y_train_a), (x_test_a, y_test_a) = mnist.load_data()

## convert
x_train_a = x_train_a.reshape(len(x_train_a), 28*28)
x_test_a = x_test_a.reshape(len(x_test_a), 28*28)

## cast the numbers to floats
x_train_a = x_train_a.astype('float32')
x_test_a = x_test_a.astype('float32')

## Normalize the inputs
x_train_a /= 255
x_test_a /= 255

num_classes_a = 10
y_train_a = keras.utils.to_categorical(y_train_a, num_classes_a)
y_test_a = keras.utils.to_categorical(y_test_a, num_classes_a)

# model_1_a
model_1_a = Sequential()
model_1_a.add(Dense(64, activation='relu', input_shape=(784,)))
model_1_a.add(Dense(10, activation='softmax'))

model_1_a.summary()

# compile the model
learning_rate_a = .0015
model_1_a.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=learning_rate_a),
              metrics=['accuracy'])

# And now let's fit.

batch_size_a = 32
epochs_a = 10
history_a = model_1_a.fit(
    x_train_a, y_train_a,
    batch_size=batch_size_a,
    epochs=epochs_a,
    verbose=1,
    validation_data=(x_test_a, y_test_a))

score_a = model_1_a.evaluate(x_test_a, y_test_a, verbose=0)
print('Test loss:', score_a[0])
print('Test accuracy:', score_a[1])

plot_loss_accuracy(history_a)
##  ANSWER FOR THE QUESTION
## model_1_a's train accuracy is ascending while validation accuracy is descending this is the sign that the model is memorazing the data
## this indicates overfitting, the reason for overfitting is we did not use drop out on model_1_a
## also the divergence of loss plots backs up the overfitting

"""### PART-2: Generalization
1. From the train set, create new train subsets by randomly selecting 60 data samples from the original train set (=0.1% of the whole train set), 600 data samples (=1%), and 6000 samples (=10%).

2. For each train subset, create a new model with same architecture as "model_1". Then, train the model on that train subset only but test on the whole original test set.

3. Plot the loss and accuracy of each model. Compare them with each other and with the plots of original "model_1" trained on the original train set. What do you observe? How does the accuracy of models change as the number of training samples increase? Do you know this phenomenon's name? Explain why it happened.

"""

# Load the data
(x_train_random, y_train_random), (x_test_random, y_test_random) = mnist.load_data()

## convert
x_train_random = x_train_random.reshape(len(x_train_random), 28*28)
x_test_random = x_test_random.reshape(len(x_test_random), 28*28)

## cast the numbers to floats
x_train_random = x_train_random.astype('float32')
x_test_random = x_test_random.astype('float32')

## Normalize the inputs
x_train_random /= 255
x_test_random /= 255

num_classes_random = 10
y_train_random = keras.utils.to_categorical(y_train_random, num_classes_random)
y_test_random = keras.utils.to_categorical(y_test_random, num_classes_random)

# Shuffle the indices of the original training set
indices = np.arange(len(x_train_random))
np.random.shuffle(indices)

# Define subset sizes: 60 (0.1%), 600 (1%), 6000 (10%)
subset_sizes = [60, 600, 6000]

# Create subsets
x_train_subsets = {}
y_train_subsets = {}

for size in subset_sizes:
    subset_indices = indices[:size]
    x_train_subsets[size] = x_train_random[subset_indices]
    y_train_subsets[size] = y_train_random[subset_indices]

model1 = Sequential()
model1.add(Dense(64, activation='relu', input_shape=(784,)))
model1.add(Dropout(0.2))
model1.add(Dense(10, activation='softmax'))

learning_rate = .0015
model1.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=learning_rate),
              metrics=['accuracy'])

history1 = model1.fit(
    x_train_subsets[60], y_train_subsets[60],
    batch_size=32,
    epochs=10,
    verbose=1,
    validation_data=(x_test_random, y_test_random)
)

score = model1.evaluate(x_test_random, y_test_random, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

plot_loss_accuracy(history1)

model2 = Sequential()
model2.add(Dense(64, activation='relu', input_shape=(784,)))
model2.add(Dropout(0.2))
model2.add(Dense(10, activation='softmax'))

learning_rate = .0015
model2.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=learning_rate),
              metrics=['accuracy'])

history2 = model2.fit(
    x_train_subsets[600], y_train_subsets[600],
    batch_size=32,
    epochs=10,
    verbose=1,
    validation_data=(x_test_random, y_test_random)
)

score = model2.evaluate(x_test_random, y_test_random, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

plot_loss_accuracy(history2)

model3 = Sequential()
model3.add(Dense(64, activation='relu', input_shape=(784,)))
model3.add(Dropout(0.2))
model3.add(Dense(10, activation='softmax'))

learning_rate = .0015
model3.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=learning_rate),
              metrics=['accuracy'])

history3 = model3.fit(
    x_train_subsets[6000], y_train_subsets[6000],
    batch_size=32,
    epochs=10,
    verbose=1,
    validation_data=(x_test_random, y_test_random)
)

score = model3.evaluate(x_test_random, y_test_random, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

plot_loss_accuracy(history3)

## ANSWER OF THE QUESTION

## Plots show that when training data increases the validation accuracy increases,
## the reason for this is the model only learns with the provided data so,
## it performs badly in the test data as test data is larger this is expected
## This phenomenon can be explained with learning curves

"""### PART-3: Build your own model
Use the Keras "Sequential" functionality to build `model_2` with the following specifications:

1. Two hidden layers.
2. First hidden layer of size 32, and second of size 48 neurons.
3. Dropout of 0.3 at each layer.
4. How many parameters does your model have?  How does it compare with model_1?
5. Train this model for 40 epochs with ADAM at a learning rate of 0.0015 and a batch size of 16.
6. Evaluate the test results.



"""

### Build your model here
from keras.optimizers import Adam

model_2 = Sequential()
model_2.add(Dense(32, activation='relu', input_shape=(784,)))
model_2.add(Dropout(0.3))
model_2.add(Dense(48, activation='relu'))
model_2.add(Dropout(0.3))
model_2.add(Dense(10, activation='softmax'))

model_2.summary()

model_2.compile(loss='categorical_crossentropy',
              optimizer=Adam(learning_rate=0.0015),
              metrics=['accuracy'])

## ANSWER FOR THE 4

## This model has 27,194 parameters, model_1 had 50,890 parameters
## this model has nearly half of model_1's parameters

(x_train_2, y_train_2), (x_test_2, y_test_2) = mnist.load_data()

x_train_2 = x_train_2.reshape(len(x_train_2), 28*28)
x_test_2 = x_test_2.reshape(len(x_test_2), 28*28)

x_train_2 = x_train_2.astype('float32')
x_test_2 = x_test_2.astype('float32')

x_train_2 /= 255
x_test_2 /= 255

y_train_2 = keras.utils.to_categorical(y_train_2, 10)
y_test_2 = keras.utils.to_categorical(y_test_2, 10)

history_2 = model_2.fit(
    x_train_2, y_train_2,
    batch_size=16,
    epochs=40,
    verbose=1,
    validation_data=(x_test_2, y_test_2)
)

score = model_2.evaluate(x_test_2, y_test_2, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

plot_loss_accuracy(history_2)

"""### PART-4: Think about the following questions

1) How do model_1 and model_2 compare?  Which do you prefer?  If you were going to put one into production, which would you choose and why?

2) Compare the trajectories of the loss function on the training set and test set for each model?  How do they compare?  What does that suggest about each model?  Do the same for accuracy.  Which do you think is more meaningful, the loss or the accuracy?

3) Suggest an improvement to model_2 (changing structure, learning rate, number of epochs, etc.) that you think will result in a better model.  Try it out below?  How much improvement can you achieve?
"""

## Answer of Question 4.1

## model_1 is larger in terms of size and also has more potential in it.
## But model_2 is more efficient.
## I would choose model_2 since it is more efficient and competitive.

## Answer of Question 4.2

## As I answered in the first part the model_1 is overfitting, and the indicator
## of this is the teaining loss and validation loss. The training loss is decreasing,
## but the validation loss is decreasing. However we don't observe this in model_2.
## The loss also shows us that the model_1 is overfitting but model_2 is in a good place.
## The key point is decreasing loss function. Even though accuracy is easier to read,
## loss gives us a more sensitive measure of how well the model is fitting.

## Answer of Question 4.3

## Increasing neuron counts on layers may help, also decreasing the drop rate may help.
## I will try it below.

## Results

## I didn't succeeded it overfitted in the as you can see below.

model_2a = Sequential()
model_2a.add(Dense(64, activation='relu', input_shape=(784,)))
model_2a.add(Dropout(0.2))
model_2a.add(Dense(64, activation='relu'))
model_2a.add(Dropout(0.2))
model_2a.add(Dense(10, activation='softmax'))

model_2a.summary()

model_2a.compile(loss='categorical_crossentropy',
              optimizer=Adam(learning_rate=0.0015),
              metrics=['accuracy'])

(x_train_2a, y_train_2a), (x_test_2a, y_test_2a) = mnist.load_data()

x_train_2a = x_train_2a.reshape(len(x_train_2a), 28*28)
x_test_2a = x_test_2a.reshape(len(x_test_2a), 28*28)

x_train_2a = x_train_2a.astype('float32')
x_test_2a = x_test_2a.astype('float32')

x_train_2a /= 255
x_test_2a /= 255

y_train_2a = keras.utils.to_categorical(y_train_2a, 10)
y_test_2a = keras.utils.to_categorical(y_test_2a, 10)

history_2a = model_2a.fit(
    x_train_2a, y_train_2a,
    batch_size=16,
    epochs=40,
    verbose=1,
    validation_data=(x_test_2a, y_test_2a)
)

score = model_2a.evaluate(x_test_2a, y_test_2a, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

plot_loss_accuracy(history_2a)